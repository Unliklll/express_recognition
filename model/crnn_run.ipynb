{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from warpctc_pytorch import CTCLoss\n",
    "import os\n",
    "import crnn.utils as utils\n",
    "import crnn.dataset as dataset\n",
    "import crnn.crnn as crnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dset = dataset.lmdbDataset(root='../data/train/telephone/tele_data/')\n",
    "dataloader = DataLoader(dset, batch_size=32, num_workers=4, collate_fn=dataset.alignCollate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nh = 100\n",
    "alphabet = '0123456789'\n",
    "nclass = len(alphabet) + 1\n",
    "nc = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "converter = utils.strLabelConverter(alphabet)\n",
    "criterion = CTCLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crnn = crnn.CRNN(32, nc, nclass, nh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crnn.cuda()\n",
    "image = image.cuda()\n",
    "criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_avg = utils.averager()\n",
    "optimizer = optim.Adadelta(crnn.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def trainBatch(net, criterion, optimizer):\n",
    "    data = train_iter.next()\n",
    "    cpu_images, cpu_texts = data\n",
    "    batch_size = cpu_images.size(0)\n",
    "    image = torch.FloatTensor(cpu_images)\n",
    "    image = Variable(image).cuda()\n",
    "    t, le = converter.encode(cpu_texts)\n",
    "    text = torch.IntTensor(t)\n",
    "    text = Variable(text)\n",
    "    length = torch.IntTensor(le)\n",
    "    length = Variable(length)\n",
    "    preds = crnn(image)\n",
    "    preds_size = Variable(torch.IntTensor([preds.size(0)] * batch_size))\n",
    "    cost = criterion(preds, text, preds_size, length) / batch_size\n",
    "    crnn.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    return cost\n",
    "\n",
    "\n",
    "for epoch in range(10000):\n",
    "    train_iter = iter(dataloader)\n",
    "    i = 0\n",
    "    while i < len(dataloader):\n",
    "        for p in crnn.parameters():\n",
    "            p.requires_grad = True\n",
    "        crnn.train()\n",
    "\n",
    "        cost = trainBatch(crnn, criterion, optimizer)\n",
    "        loss_avg.add(cost)\n",
    "        i += 1\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print('[%d/%d][%d/%d] Loss: %f' %\n",
    "                  (epoch, 10, i, len(dataloader), loss_avg.val()))\n",
    "            loss_avg.reset()\n",
    "\n",
    "#         if i % opt.valInterval == 0:\n",
    "#             val(crnn, test_dataset, criterion)\n",
    "\n",
    "        # do checkpointing\n",
    "#         if i % opt.saveInterval == 0:\n",
    "#             torch.save(\n",
    "#                 crnn.state_dict(),\n",
    "#                 '{0}/netCRNN_{1}_{2}.pth'.format(opt.experiment, epoch, i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118882--22---55-----11111244111-1 => 1822512411          \n"
     ]
    }
   ],
   "source": [
    "import PIL.Image as Image\n",
    "img_path = '../data/train/telephone/telephone/18.png'\n",
    "transformer = dataset.resizeNormalize((128, 32))\n",
    "image = Image.open(img_path).convert('L')\n",
    "image = transformer(image).cuda()\n",
    "image = image.view(1, *image.size())\n",
    "image = Variable(image)\n",
    "\n",
    "crnn.eval()\n",
    "preds = crnn(image)\n",
    "_, preds = preds.max(2)\n",
    "preds = preds.squeeze(2)\n",
    "preds = preds.transpose(1, 0).contiguous().view(-1)\n",
    "preds_size = Variable(torch.IntTensor([preds.size(0)]))\n",
    "raw_pred = converter.decode(preds.data, preds_size.data, raw=True)\n",
    "sim_pred = converter.decode(preds.data, preds_size.data, raw=False)\n",
    "print('%-20s => %-20s' % (raw_pred, sim_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
