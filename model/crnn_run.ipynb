{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from warpctc_pytorch import CTCLoss\n",
    "import os\n",
    "import crnn.utils as utils\n",
    "import crnn.dataset as dataset\n",
    "import crnn.crnn as crnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'crnn.dataset' has no attribute 'lmdbDataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-06c773d3b766>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlmdbDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'../data/train/telephone/tele_data/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malignCollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'crnn.dataset' has no attribute 'lmdbDataset'"
     ]
    }
   ],
   "source": [
    "dset = dataset.lmdbDataset(root='../data/train/telephone/tele_data/')\n",
    "dataloader = DataLoader(dset, batch_size=32, num_workers=4, collate_fn=dataset.alignCollate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8f7ce3189ea3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mcrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image' is not defined"
     ]
    }
   ],
   "source": [
    "nh = 100\n",
    "alphabet = '0123456789'\n",
    "nclass = len(alphabet) + 1\n",
    "nc = 1\n",
    "\n",
    "converter = utils.strLabelConverter(alphabet)\n",
    "criterion = CTCLoss()\n",
    "\n",
    "crnn = crnn.CRNN(32, nc, nclass, nh)\n",
    "\n",
    "crnn.cuda()\n",
    "image = image.cuda()\n",
    "criterion = criterion.cuda()\n",
    "\n",
    "loss_avg = utils.averager()\n",
    "optimizer = optim.Adadelta(crnn.parameters(), lr=1e-3)\n",
    "\n",
    "def trainBatch(net, criterion, optimizer):\n",
    "    data = train_iter.next()\n",
    "    cpu_images, cpu_texts = data\n",
    "    batch_size = cpu_images.size(0)\n",
    "    image = torch.FloatTensor(cpu_images)\n",
    "    image = Variable(image).cuda()\n",
    "    t, le = converter.encode(cpu_texts)\n",
    "    text = torch.IntTensor(t)\n",
    "    text = Variable(text)\n",
    "    length = torch.IntTensor(le)\n",
    "    length = Variable(length)\n",
    "    preds = crnn(image)\n",
    "    preds_size = Variable(torch.IntTensor([preds.size(0)] * batch_size))\n",
    "    cost = criterion(preds, text, preds_size, length) / batch_size\n",
    "    crnn.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    return cost\n",
    "\n",
    "\n",
    "for epoch in range(10000):\n",
    "    train_iter = iter(dataloader)\n",
    "    i = 0\n",
    "    while i < len(dataloader):\n",
    "        for p in crnn.parameters():\n",
    "            p.requires_grad = True\n",
    "        crnn.train()\n",
    "\n",
    "        cost = trainBatch(crnn, criterion, optimizer)\n",
    "        loss_avg.add(cost)\n",
    "        i += 1\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print('[%d/%d][%d/%d] Loss: %f' %\n",
    "                  (epoch, 10, i, len(dataloader), loss_avg.val()))\n",
    "            loss_avg.reset()\n",
    "\n",
    "#         if i % opt.valInterval == 0:\n",
    "#             val(crnn, test_dataset, criterion)\n",
    "\n",
    "        # do checkpointing\n",
    "#         if i % opt.saveInterval == 0:\n",
    "#             torch.save(\n",
    "#                 crnn.state_dict(),\n",
    "#                 '{0}/netCRNN_{1}_{2}.pth'.format(opt.experiment, epoch, i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import PIL.Image as Image\n",
    "img_path = '../data/train/telephone/telephone/18.png'\n",
    "transformer = dataset.resizeNormalize((128, 32))\n",
    "image = Image.open(img_path).convert('L')\n",
    "image = transformer(image).cuda()\n",
    "image = image.view(1, *image.size())\n",
    "image = Variable(image)\n",
    "\n",
    "crnn.eval()\n",
    "preds = crnn(image)\n",
    "_, preds = preds.max(2)\n",
    "preds = preds.squeeze(2)\n",
    "preds = preds.transpose(1, 0).contiguous().view(-1)\n",
    "preds_size = Variable(torch.IntTensor([preds.size(0)]))\n",
    "raw_pred = converter.decode(preds.data, preds_size.data, raw=True)\n",
    "sim_pred = converter.decode(preds.data, preds_size.data, raw=False)\n",
    "print('%-20s => %-20s' % (raw_pred, sim_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
