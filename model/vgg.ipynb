{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 数据预处理，做一些scale，随机crop，normalizaiotn到0-1之间\n",
    "img_transform = {\n",
    "    'train': transforms.Compose([\n",
    "            transforms.Scale(150),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor()\n",
    "#             transforms.Normalize((0, 0, 0), (255, 255, 255))\n",
    "        ]),\n",
    "    'val': transforms.Compose([\n",
    "            transforms.Scale(150),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor()\n",
    "#             transforms.Normalize((0, 0, 0), (255, 255, 255))\n",
    "        ])\n",
    "}\n",
    "\n",
    "root_path = '../data'\n",
    "\n",
    "#读取数据文件夹\n",
    "dset = {\n",
    "    'train': ImageFolder(os.path.join(root_path, 'train/province'), transform=img_transform['train']),\n",
    "    'val': ImageFolder(os.path.join(root_path, 'val/province'), transform=img_transform['val'])\n",
    "}\n",
    "\n",
    "#读取数据\n",
    "dataloader = {\n",
    "    'train': DataLoader(dset['train'], batch_size=16, shuffle=True, num_workers=4),\n",
    "    'val': DataLoader(dset['val'], batch_size=16, num_workers=4)\n",
    "}\n",
    "\n",
    "# img, label = iter(dataloader['train']).next()\n",
    "\n",
    "# a = img[0].numpy()\n",
    "# a = np.transpose(a, (1, 2, 0))\n",
    "# plt.imshow(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6f7661bf60>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f76ba3278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = iter(dataloader['train']).next()\n",
    "\n",
    "a = img[0].numpy()\n",
    "a = np.transpose(a, (1, 2, 0))\n",
    "plt.imshow(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#确定数据size\n",
    "data_size = {\n",
    "    x: len(dataloader[x].dataset.imgs)\n",
    "    for x in ['train', 'val']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of train data set: 300\n",
      "size of validation data set: 4\n"
     ]
    }
   ],
   "source": [
    "print('size of train data set: {}'.format(data_size['train']))# 每个文件夹放了一张图片做一个示例\n",
    "print('size of validation data set: {}'.format(data_size['val']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_classes = dataloader['train'].dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class of province: ['anhui', 'guangdong', 'jiangsu', 'shanghai', 'sichaun', 'zhejiang']\n"
     ]
    }
   ],
   "source": [
    "# 创建了三个省份作为示例，顺序按照文件夹的顺序\n",
    "print('class of province: {}'.format(img_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#判断能不能用cuda，增加鲁棒性\n",
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in my computer, cuda availabel? \n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(\"in my computer, cuda availabel? \\n{}\".format(use_gpu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build vgg net\n",
    "之所以选择vgg因为这个问题不需要太复杂的网络，所以选择了一个相对简单的网络结构  \n",
    "详细网络结构见下面网址\n",
    "http://ethereon.github.io/netscope/#/gist/dc5003de6943ea5a6b8b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class vgg16(nn.Module):\n",
    "    def __init__(self, in_c, out_class):\n",
    "        super(vgg16, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "                nn.Conv2d(in_c, 64, 3, stride=1, padding=1),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(64, 64, 3, stride=1, padding=1),\n",
    "                nn.ReLU(True)\n",
    "            )\n",
    "        self.conv2 = nn.Sequential(\n",
    "                nn.Conv2d(64, 128, 3, stride=1, padding=1),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
    "                nn.ReLU(True)\n",
    "            )\n",
    "        self.conv3 = nn.Sequential(\n",
    "                nn.Conv2d(128, 256, 3, stride=1, padding=1),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(256, 256, 3, stride=1, padding=1),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(256, 256, 3, stride=1, padding=1),\n",
    "                nn.ReLU(True),\n",
    "                nn.AvgPool2d(40)\n",
    "            )\n",
    "#         self.conv4 = nn.Sequential(\n",
    "#                 nn.Conv2d(256, 512, 3, stride=1, padding=1),\n",
    "#                 nn.ReLU(True),\n",
    "#                 nn.Conv2d(512, 512, 3, stride=1, padding=1),\n",
    "#                 nn.ReLU(True),\n",
    "#                 nn.Conv2d(512, 512, 3, stride=1, padding=1),\n",
    "#                 nn.ReLU(True)\n",
    "#             )\n",
    "#         self.conv5 = nn.Sequential(\n",
    "#                 nn.Conv2d(512, 512, 3, stride=1, padding=1),\n",
    "#                 nn.ReLU(True),\n",
    "#                 nn.Conv2d(512, 512, 3, stride=1, padding=1),\n",
    "#                 nn.ReLU(True),\n",
    "#                 nn.Conv2d(512, 512, 3, stride=1, padding=1),\n",
    "#                 nn.ReLU(True)\n",
    "#             )\n",
    "        self.fc1 = nn.Linear(256, out_class)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.max_pool2d(x, 2, stride=2)\n",
    "        x = self.conv2(x)\n",
    "        x = F.max_pool2d(x, 2, stride=2)\n",
    "        x = self.conv3(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mynet = vgg16(3, 6)\n",
    "mynet = torchvision.models.resnet101()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.children of ResNet (\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (relu): ReLU (inplace)\n",
       "  (maxpool): MaxPool2d (size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1))\n",
       "  (layer1): Sequential (\n",
       "    (0): Bottleneck (\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "      (downsample): Sequential (\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck (\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "    )\n",
       "    (2): Bottleneck (\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential (\n",
       "    (0): Bottleneck (\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "      (downsample): Sequential (\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck (\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "    )\n",
       "    (2): Bottleneck (\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "    )\n",
       "    (3): Bottleneck (\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential (\n",
       "    (0): Bottleneck (\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "      (downsample): Sequential (\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck (\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "    )\n",
       "    (2): Bottleneck (\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "    )\n",
       "    (3): Bottleneck (\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "    )\n",
       "    (4): Bottleneck (\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "    )\n",
       "    (5): Bottleneck (\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "    )\n",
       "    (6): Bottleneck (\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "    )\n",
       "    (7): Bottleneck (\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "    )\n",
       "    (8): Bottleneck (\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "    )\n",
       "    (9): Bottleneck (\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "    )\n",
       "    (10): Bottleneck (\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "    )\n",
       "    (11): Bottleneck (\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "    )\n",
       "    (12): Bottleneck (\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "    )\n",
       "    (13): Bottleneck (\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "    )\n",
       "    (14): Bottleneck (\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "    )\n",
       "    (15): Bottleneck (\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "    )\n",
       "    (16): Bottleneck (\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "    )\n",
       "    (17): Bottleneck (\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "    )\n",
       "    (18): Bottleneck (\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "    )\n",
       "    (19): Bottleneck (\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "    )\n",
       "    (20): Bottleneck (\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "    )\n",
       "    (21): Bottleneck (\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "    )\n",
       "    (22): Bottleneck (\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential (\n",
       "    (0): Bottleneck (\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "      (downsample): Sequential (\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck (\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "    )\n",
       "    (2): Bottleneck (\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d (\n",
       "  )\n",
       "  (fc): Linear (2048 -> 1000)\n",
       ")>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mynet.children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mynet.fc = nn.Sequential(nn.Linear(2048, 1000),\n",
    "                         nn.ReLU(True),\n",
    "                         nn.Linear(1000, 500),\n",
    "                         nn.ReLU(True),\n",
    "                         nn.Linear(500, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mynet.classifier = nn.Sequential(nn.Linear(25088, 4096), \n",
    "                                 nn.ReLU(True), \n",
    "                                 nn.Dropout(0.5),\n",
    "                                 nn.Linear(4096, 400),\n",
    "                                 nn.ReLU(True),\n",
    "                                 nn.Dropout(0.5),\n",
    "                                 nn.Linear(400, 2),\n",
    "                                 nn.Softmax()\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    mynet = mynet.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print('network structure:')\n",
    "#mynet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define optimizer and loss\n",
    "optimizer = optim.SGD(mynet.parameters(), lr=1e-3, momentum=0.9) \n",
    "# 随机梯度下降，之后可以选择别的速度更快的如rmsprop\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### begin train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epoch = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "**********\n",
      "0.1429455820719401\n",
      "0.9433333333333334\n",
      "\n",
      "1\n",
      "**********\n",
      "0.11004836201667785\n",
      "0.97\n",
      "\n",
      "2\n",
      "**********\n",
      "0.08590604305267334\n",
      "0.9833333333333333\n",
      "\n",
      "3\n",
      "**********\n",
      "0.11633285683890184\n",
      "0.9633333333333334\n",
      "\n",
      "4\n",
      "**********\n",
      "0.14628564760088922\n",
      "0.9533333333333334\n",
      "\n",
      "5\n",
      "**********\n",
      "0.08888313135753076\n",
      "0.9733333333333334\n",
      "\n",
      "6\n",
      "**********\n",
      "0.11228568548957507\n",
      "0.97\n",
      "\n",
      "7\n",
      "**********\n",
      "0.11559133214255174\n",
      "0.9566666666666667\n",
      "\n",
      "8\n",
      "**********\n",
      "0.05041427771250407\n",
      "0.99\n",
      "\n",
      "9\n",
      "**********\n",
      "0.22360282103220622\n",
      "0.9066666666666666\n",
      "\n",
      "10\n",
      "**********\n",
      "0.05817950407663981\n",
      "0.9866666666666667\n",
      "\n",
      "11\n",
      "**********\n",
      "0.18343658129374185\n",
      "0.93\n",
      "\n",
      "12\n",
      "**********\n",
      "0.2781949603557587\n",
      "0.9\n",
      "\n",
      "13\n",
      "**********\n",
      "0.3012975118557612\n",
      "0.8866666666666667\n",
      "\n",
      "14\n",
      "**********\n",
      "0.1621862002213796\n",
      "0.9466666666666667\n",
      "\n",
      "15\n",
      "**********\n",
      "0.17496077835559845\n",
      "0.9366666666666666\n",
      "\n",
      "16\n",
      "**********\n",
      "0.165866010983785\n",
      "0.9433333333333334\n",
      "\n",
      "17\n",
      "**********\n",
      "0.07011992295583089\n",
      "0.9866666666666667\n",
      "\n",
      "18\n",
      "**********\n",
      "0.05185392061869303\n",
      "0.9866666666666667\n",
      "\n",
      "19\n",
      "**********\n",
      "0.021410190239548682\n",
      "1.0\n",
      "\n",
      "20\n",
      "**********\n",
      "0.02298121294627587\n",
      "1.0\n",
      "\n",
      "21\n",
      "**********\n",
      "0.010810144692659378\n",
      "1.0\n",
      "\n",
      "22\n",
      "**********\n",
      "0.016461850808312497\n",
      "0.9933333333333333\n",
      "\n",
      "23\n",
      "**********\n",
      "0.09214112917737415\n",
      "0.97\n",
      "\n",
      "24\n",
      "**********\n",
      "0.24169442166884741\n",
      "0.9066666666666666\n",
      "\n",
      "25\n",
      "**********\n",
      "0.17257238745689393\n",
      "0.93\n",
      "\n",
      "26\n",
      "**********\n",
      "0.07119086623191834\n",
      "0.9733333333333334\n",
      "\n",
      "27\n",
      "**********\n",
      "0.033945256968339284\n",
      "0.9966666666666667\n",
      "\n",
      "28\n",
      "**********\n",
      "0.04354512214660645\n",
      "0.9833333333333333\n",
      "\n",
      "29\n",
      "**********\n",
      "0.037250488599141436\n",
      "0.99\n",
      "\n",
      "30\n",
      "**********\n",
      "0.04377788384755452\n",
      "0.9866666666666667\n",
      "\n",
      "31\n",
      "**********\n",
      "0.014896190961201986\n",
      "1.0\n",
      "\n",
      "32\n",
      "**********\n",
      "0.006282606127982338\n",
      "1.0\n",
      "\n",
      "33\n",
      "**********\n",
      "0.01220683256474634\n",
      "1.0\n",
      "\n",
      "34\n",
      "**********\n",
      "0.008272094723458091\n",
      "0.9966666666666667\n",
      "\n",
      "35\n",
      "**********\n",
      "0.006534846623738607\n",
      "1.0\n",
      "\n",
      "36\n",
      "**********\n",
      "0.006485970813470582\n",
      "1.0\n",
      "\n",
      "37\n",
      "**********\n",
      "0.03463088313738505\n",
      "0.9866666666666667\n",
      "\n",
      "38\n",
      "**********\n",
      "0.02297590414683024\n",
      "0.9933333333333333\n",
      "\n",
      "39\n",
      "**********\n",
      "0.06305930376052857\n",
      "0.97\n",
      "\n",
      "40\n",
      "**********\n",
      "0.028019504545566936\n",
      "0.9933333333333333\n",
      "\n",
      "41\n",
      "**********\n",
      "0.03730144184082747\n",
      "0.99\n",
      "\n",
      "42\n",
      "**********\n",
      "0.009279826488345862\n",
      "1.0\n",
      "\n",
      "43\n",
      "**********\n",
      "0.013816374093294144\n",
      "0.9966666666666667\n",
      "\n",
      "44\n",
      "**********\n",
      "0.06229073842521757\n",
      "0.9766666666666667\n",
      "\n",
      "45\n",
      "**********\n",
      "0.0429431581373016\n",
      "0.99\n",
      "\n",
      "46\n",
      "**********\n",
      "0.0915334844092528\n",
      "0.9666666666666667\n",
      "\n",
      "47\n",
      "**********\n",
      "0.04543749333669742\n",
      "0.9866666666666667\n",
      "\n",
      "48\n",
      "**********\n",
      "0.1494581397374471\n",
      "0.9433333333333334\n",
      "\n",
      "49\n",
      "**********\n",
      "0.05059671560923258\n",
      "0.9833333333333333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epoch):\n",
    "    print(epoch)\n",
    "    print('*'*10)\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    for data in dataloader['train']:\n",
    "        img, label = data\n",
    "        img = Variable(img).cuda()\n",
    "        label = Variable(label).cuda()\n",
    "        \n",
    "        out = mynet(img)\n",
    "        loss = criterion(out, label)\n",
    "        _, pred = torch.max(out, 1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.data[0] * label.size(0)\n",
    "        num_correct = torch.sum(pred==label)\n",
    "        running_acc += num_correct.data[0]\n",
    "    running_loss /= data_size['train']\n",
    "    running_acc /= data_size['train']\n",
    "    print(running_loss)\n",
    "    print(running_acc)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = dataloader['val']\n",
    "img, label = iter(a).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1\n",
       " 0\n",
       " 5\n",
       " 5\n",
       "[torch.LongTensor of size 4]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anhui', 'guangdong', 'jiangsu', 'shanghai', 'sichaun', 'zhejiang']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1\n",
       " 0\n",
       " 5\n",
       " 2\n",
       "[torch.cuda.LongTensor of size 4x1 (GPU 0)]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1 = Variable(img).cuda()\n",
    "\n",
    "pre = mynet(img1)\n",
    "\n",
    "_, aa = torch.max(pre, 1)\n",
    "\n",
    "# aa = aa.data[0]\n",
    "# aa = aa.cpu().numpy()\n",
    "\n",
    "# img_classes[aa]\n",
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6f74966d30>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f69a0b198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pim = img[0].numpy()\n",
    "\n",
    "pim = np.transpose(pim, (1, 2, 0))\n",
    "\n",
    "plt.imshow(pim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1.3115  1.8818  8.4755  7.2688 -9.3902 -6.0596\n",
       "[torch.cuda.FloatTensor of size 1x6 (GPU 0)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/50\n",
      "----------\n",
      "1/1, Loss: 1.7920, Acc:0.1688\n",
      "train Loss:1.7917 Acc:0.1633\n",
      "complete in 0m 16 s\n",
      "\n",
      "2/50\n",
      "----------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (2) : out of memory at /home/sherlock/Documents/pytorch/torch/lib/THC/generic/THCStorage.cu:66",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-35e2dd46a27f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 将梯度归零\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# log statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sherlock/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_variables)\u001b[0m\n\u001b[1;32m    144\u001b[0m                     'or with gradient w.r.t. the variable')\n\u001b[1;32m    145\u001b[0m             \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_as_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execution_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sherlock/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/_functions/linear.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad_output)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mgrad_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_input_grad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mgrad_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_input_grad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mgrad_bias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (2) : out of memory at /home/sherlock/Documents/pytorch/torch/lib/THC/generic/THCStorage.cu:66"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epoch): # 开始每个epoch\n",
    "    since = time.time() # 取得当前时间\n",
    "    print('{}/{}'.format(epoch+1, num_epoch))\n",
    "    print('-'*10)\n",
    "\n",
    "#     for phase in ['train', 'val']: # 判断是train还是validation\n",
    "#     if phase == 'train':\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    for i, data in enumerate(dataloader['train'], 1):\n",
    "        img, label = data\n",
    "        if use_gpu:\n",
    "            img = Variable(img).cuda()\n",
    "            label = Variable(label).cuda()\n",
    "        else:\n",
    "            img = Variable(img)\n",
    "            label = Variable(label)\n",
    "\n",
    "        # forward\n",
    "        output = mynet(img)\n",
    "        _, pred = torch.max(output, 1)\n",
    "        loss = criterion(output, label)\n",
    "        # backward\n",
    "#         if phase == 'train': # 如果是train，则反向传播更新参数\n",
    "\n",
    "        optimizer.zero_grad() # 将梯度归零\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # log statistics\n",
    "        running_loss += loss.data[0] * label.size(0)\n",
    "        num_correct = torch.sum(pred == label)\n",
    "        running_acc += num_correct.data[0]\n",
    "        if i % 10 == 0:\n",
    "            print('{}/{}, Loss: {:.4f}, Acc:{:.4f}'.format(i//10, data_size['train']//(10*16), \n",
    "                                                   running_loss/(i*16), running_acc/(i*16)))\n",
    "        \n",
    "    running_loss /= data_size['train']\n",
    "    running_acc /= data_size['train']\n",
    "    print('{} Loss:{:.4f} Acc:{:.4f}'.format('train', running_loss, running_acc))\n",
    "    time_eplise = time.time() - since\n",
    "    print('complete in {:.0f}m {:.0f} s'.format(time_eplise//60, time_eplise%60))\n",
    "#             if phase == 'val' and running_acc > best_acc: # 根据validation 判断更新之后的model是否更好\n",
    "#                 best_acc = running_acc\n",
    "#                 best_model = copy.deepcopy(model)\n",
    "\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "#     best_model = model\n",
    "#     best_acc = 0.0\n",
    "        \n",
    "for epoch in range(num_epoch): # 开始每个epoch\n",
    "    since = time.time() # 取得当前时间\n",
    "    print('{}/{}'.format(epoch+1, num_epoch))\n",
    "    print('-'*10)\n",
    "\n",
    "    for phase in ['train', 'val']: # 判断是train还是validation\n",
    "        if phase == 'train':\n",
    "            optimizer.zero_grad() # 将梯度归零\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        for data in dataloader[phase]:\n",
    "            img, label = data\n",
    "            if use_gpu:\n",
    "                img = Variable(img).cuda()\n",
    "                label = Variable(label).cuda()\n",
    "            else:\n",
    "                img = Variable(img)\n",
    "                label = Variable(label)\n",
    "\n",
    "            # forward\n",
    "            output = mynet(img)\n",
    "            _, pred = torch.max(output, 1)\n",
    "            loss = criterion(output, label)\n",
    "            # backward\n",
    "            if phase == 'train': # 如果是train，则反向传播更新参数\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            # log statistics\n",
    "            running_loss += loss.data[0] * label.size(0)\n",
    "            num_correct = torch.sum(pred == label)\n",
    "            running_acc += num_correct.data[0]\n",
    "\n",
    "        running_loss /= data_size[phase]\n",
    "        running_acc /= data_size[phase]\n",
    "        print('{} Loss:{:.4f} Acc:{:.4f}'.format(phase, running_loss, running_acc))\n",
    "    time_eplise = time.time() - since\n",
    "    print('comlete in {:.0f}m{:.0f}s'.format(epoch+1, num_epoch,time_eplise//60, time_eplise%60))\n",
    "#             if phase == 'val' and running_acc > best_acc: # 根据validation 判断更新之后的model是否更好\n",
    "#                 best_acc = running_acc\n",
    "#                 best_model = copy.deepcopy(model)\n",
    "\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
