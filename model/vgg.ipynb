{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import os\n",
    "import time\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 数据预处理，做一些scale，随机crop，normalizaiotn到0-1之间\n",
    "img_transform = {\n",
    "    'train': transforms.Compose([\n",
    "            transforms.Scale(300),\n",
    "            transforms.RandomCrop(224),\n",
    "            transforms.ToTensor()\n",
    "#             transforms.Normalize((0, 0, 0), (255, 255, 255))\n",
    "        ]),\n",
    "    'val': transforms.Compose([\n",
    "            transforms.Scale(300),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor()\n",
    "#             transforms.Normalize((0, 0, 0), (255, 255, 255))\n",
    "        ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root_path = '../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#读取数据文件夹\n",
    "dset = {\n",
    "    x: ImageFolder(os.path.join(root_path, x), transform=img_transform[x])\n",
    "    for x in ['train', 'val']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#读取数据\n",
    "dataloader = {\n",
    "    'train': DataLoader(dset['train'], batch_size=16, shuffle=True, num_workers=4),\n",
    "    'val': DataLoader(dset['val'], batch_size=16, num_workers=4)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#确定数据size\n",
    "data_size = {\n",
    "    x: len(dataloader[x].dataset.imgs)\n",
    "    for x in ['train', 'val']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of train data set: 2121\n",
      "size of validation data set: 400\n"
     ]
    }
   ],
   "source": [
    "print('size of train data set: {}'.format(data_size['train']))# 每个文件夹放了一张图片做一个示例\n",
    "print('size of validation data set: {}'.format(data_size['val']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_classes = dataloader['train'].dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class of province: ['cat', 'dog']\n"
     ]
    }
   ],
   "source": [
    "# 创建了三个省份作为示例，顺序按照文件夹的顺序\n",
    "print('class of province: {}'.format(img_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#判断能不能用cuda，增加鲁棒性\n",
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in my computer, cuda availabel? \n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(\"in my computer, cuda availabel? \\n{}\".format(use_gpu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build vgg net\n",
    "之所以选择vgg因为这个问题不需要太复杂的网络，所以选择了一个相对简单的网络结构  \n",
    "详细网络结构见下面网址\n",
    "http://ethereon.github.io/netscope/#/gist/dc5003de6943ea5a6b8b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class vgg16(nn.Module):\n",
    "    def __init__(self, in_c, out_class):\n",
    "        super(vgg16, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "                nn.Conv2d(in_c, 64, 3, stride=1, padding=1),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(64, 64, 3, stride=1, padding=1),\n",
    "                nn.ReLU(True)\n",
    "            )\n",
    "        self.conv2 = nn.Sequential(\n",
    "                nn.Conv2d(64, 128, 3, stride=1, padding=1),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
    "                nn.ReLU(True)\n",
    "            )\n",
    "        self.conv3 = nn.Sequential(\n",
    "                nn.Conv2d(128, 256, 3, stride=1, padding=1),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(256, 256, 3, stride=1, padding=1),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(256, 256, 3, stride=1, padding=1),\n",
    "                nn.ReLU(True)\n",
    "            )\n",
    "        self.conv4 = nn.Sequential(\n",
    "                nn.Conv2d(256, 512, 3, stride=1, padding=1),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(512, 512, 3, stride=1, padding=1),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(512, 512, 3, stride=1, padding=1),\n",
    "                nn.ReLU(True)\n",
    "            )\n",
    "        self.conv5 = nn.Sequential(\n",
    "                nn.Conv2d(512, 512, 3, stride=1, padding=1),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(512, 512, 3, stride=1, padding=1),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(512, 512, 3, stride=1, padding=1),\n",
    "                nn.ReLU(True)\n",
    "            )\n",
    "        self.fc1 = nn.Sequential(\n",
    "                nn.Linear(512 * 7 * 7, 4096),\n",
    "                nn.ReLU(True),\n",
    "                nn.Dropout(0.5),\n",
    "                nn.Linear(4096, 1000),\n",
    "                nn.ReLU(True),\n",
    "                nn.Dropout(0.5)\n",
    "            )\n",
    "        self.fc2 = nn.Sequential(\n",
    "                nn.Linear(1000, 500),\n",
    "                nn.ReLU(True),\n",
    "                nn.Dropout(0.5)\n",
    "            )\n",
    "        self.fc3 = nn.Linear(500, out_class)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = F.max_pool2d(out, 2, stride=2)\n",
    "        out = self.conv2(out)\n",
    "        out = F.max_pool2d(out, 2, stride=2)\n",
    "        out = self.conv3(out)\n",
    "        out = F.max_pool2d(out, 2, stride=2)\n",
    "        out = self.conv4(out)\n",
    "        out = F.max_pool2d(out, 2, stride=2)\n",
    "        out = self.conv5(out)\n",
    "        out = F.max_pool2d(out, 2, stride=2)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mynet = vgg16(3, 2)\n",
    "mynet = torchvision.models.vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mynet.classifier = nn.Sequential(nn.Linear(25088, 4096), \n",
    "                                 nn.ReLU(True), \n",
    "                                 nn.Dropout(0.5),\n",
    "                                 nn.Linear(4096, 400),\n",
    "                                 nn.ReLU(True),\n",
    "                                 nn.Dropout(0.5),\n",
    "                                 nn.Linear(400, 2),\n",
    "                                 nn.Softmax()\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    mynet = mynet.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print('network structure:')\n",
    "#mynet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define optimizer and loss\n",
    "optimizer = optim.SGD(mynet.parameters(), lr=1e-2, momentum=0.9, nesterov=True) \n",
    "# 随机梯度下降，之后可以选择别的速度更快的如rmsprop\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### begin train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/10\n",
      "----------\n",
      "1/13, Loss: 0.6912, Acc:0.5625\n",
      "2/13, Loss: 0.6981, Acc:0.5500\n",
      "3/13, Loss: 0.7121, Acc:0.5104\n",
      "4/13, Loss: 0.7071, Acc:0.5188\n",
      "5/13, Loss: 0.7116, Acc:0.5025\n",
      "6/13, Loss: 0.7096, Acc:0.5062\n",
      "7/13, Loss: 0.7081, Acc:0.5080\n",
      "8/13, Loss: 0.7079, Acc:0.5094\n",
      "9/13, Loss: 0.7072, Acc:0.5132\n",
      "10/13, Loss: 0.7093, Acc:0.5081\n",
      "11/13, Loss: 0.7207, Acc:0.5034\n",
      "12/13, Loss: 0.7259, Acc:0.5062\n",
      "13/13, Loss: 0.7357, Acc:0.5010\n",
      "train Loss:0.7355 Acc:0.5021\n",
      "complete in 1m 52 s\n",
      "\n",
      "2/10\n",
      "----------\n",
      "1/13, Loss: 0.8169, Acc:0.4938\n",
      "2/13, Loss: 0.8370, Acc:0.4750\n",
      "3/13, Loss: 0.8332, Acc:0.4792\n",
      "4/13, Loss: 0.8173, Acc:0.4953\n",
      "5/13, Loss: 0.8227, Acc:0.4900\n",
      "6/13, Loss: 0.8087, Acc:0.5042\n",
      "7/13, Loss: 0.8120, Acc:0.5009\n",
      "8/13, Loss: 0.8145, Acc:0.4984\n",
      "9/13, Loss: 0.8164, Acc:0.4965\n",
      "10/13, Loss: 0.8099, Acc:0.5031\n",
      "11/13, Loss: 0.8079, Acc:0.5051\n",
      "12/13, Loss: 0.8089, Acc:0.5042\n",
      "13/13, Loss: 0.8087, Acc:0.5043\n",
      "train Loss:0.8081 Acc:0.5050\n",
      "complete in 1m 53 s\n",
      "\n",
      "3/10\n",
      "----------\n",
      "1/13, Loss: 0.8133, Acc:0.5000\n",
      "2/13, Loss: 0.7570, Acc:0.5563\n",
      "3/13, Loss: 0.7466, Acc:0.5667\n",
      "4/13, Loss: 0.7695, Acc:0.5437\n",
      "5/13, Loss: 0.7708, Acc:0.5425\n",
      "6/13, Loss: 0.7831, Acc:0.5302\n",
      "7/13, Loss: 0.7883, Acc:0.5250\n",
      "8/13, Loss: 0.7914, Acc:0.5219\n",
      "9/13, Loss: 0.7924, Acc:0.5208\n",
      "10/13, Loss: 0.7964, Acc:0.5169\n",
      "11/13, Loss: 0.8002, Acc:0.5131\n",
      "12/13, Loss: 0.8065, Acc:0.5068\n",
      "13/13, Loss: 0.8046, Acc:0.5087\n",
      "train Loss:0.8036 Acc:0.5097\n",
      "complete in 1m 54 s\n",
      "\n",
      "4/10\n",
      "----------\n",
      "1/13, Loss: 0.7758, Acc:0.5375\n",
      "2/13, Loss: 0.7976, Acc:0.5156\n",
      "3/13, Loss: 0.8028, Acc:0.5104\n",
      "4/13, Loss: 0.8117, Acc:0.5016\n",
      "5/13, Loss: 0.8158, Acc:0.4975\n",
      "6/13, Loss: 0.8133, Acc:0.5000\n",
      "7/13, Loss: 0.8159, Acc:0.4973\n",
      "8/13, Loss: 0.8086, Acc:0.5047\n",
      "9/13, Loss: 0.7994, Acc:0.5139\n",
      "10/13, Loss: 0.8014, Acc:0.5119\n",
      "11/13, Loss: 0.7996, Acc:0.5136\n",
      "12/13, Loss: 0.7997, Acc:0.5135\n",
      "13/13, Loss: 0.8012, Acc:0.5120\n",
      "train Loss:0.8012 Acc:0.5120\n",
      "complete in 1m 52 s\n",
      "\n",
      "5/10\n",
      "----------\n",
      "1/13, Loss: 0.8258, Acc:0.4875\n",
      "2/13, Loss: 0.7851, Acc:0.5281\n",
      "3/13, Loss: 0.7674, Acc:0.5458\n",
      "4/13, Loss: 0.7820, Acc:0.5312\n",
      "5/13, Loss: 0.7970, Acc:0.5162\n",
      "6/13, Loss: 0.7903, Acc:0.5229\n",
      "7/13, Loss: 0.7927, Acc:0.5205\n",
      "8/13, Loss: 0.7976, Acc:0.5156\n",
      "9/13, Loss: 0.8028, Acc:0.5104\n",
      "10/13, Loss: 0.8033, Acc:0.5100\n",
      "11/13, Loss: 0.8030, Acc:0.5102\n",
      "12/13, Loss: 0.8028, Acc:0.5104\n",
      "13/13, Loss: 0.8003, Acc:0.5130\n",
      "train Loss:0.8003 Acc:0.5130\n",
      "complete in 1m 51 s\n",
      "\n",
      "6/10\n",
      "----------\n",
      "1/13, Loss: 0.8320, Acc:0.4813\n",
      "2/13, Loss: 0.8320, Acc:0.4813\n",
      "3/13, Loss: 0.8195, Acc:0.4938\n",
      "4/13, Loss: 0.8070, Acc:0.5062\n",
      "5/13, Loss: 0.8120, Acc:0.5012\n",
      "6/13, Loss: 0.8143, Acc:0.4990\n",
      "7/13, Loss: 0.8017, Acc:0.5116\n",
      "8/13, Loss: 0.7969, Acc:0.5164\n",
      "9/13, Loss: 0.7980, Acc:0.5153\n",
      "10/13, Loss: 0.8001, Acc:0.5131\n",
      "11/13, Loss: 0.8002, Acc:0.5131\n",
      "12/13, Loss: 0.8013, Acc:0.5120\n",
      "13/13, Loss: 0.8046, Acc:0.5087\n",
      "train Loss:0.8022 Acc:0.5111\n",
      "complete in 1m 51 s\n",
      "\n",
      "7/10\n",
      "----------\n",
      "1/13, Loss: 0.8133, Acc:0.5000\n",
      "2/13, Loss: 0.7945, Acc:0.5188\n",
      "3/13, Loss: 0.7987, Acc:0.5146\n",
      "4/13, Loss: 0.7851, Acc:0.5281\n",
      "5/13, Loss: 0.7995, Acc:0.5138\n",
      "6/13, Loss: 0.8018, Acc:0.5115\n",
      "7/13, Loss: 0.8025, Acc:0.5107\n",
      "8/13, Loss: 0.8031, Acc:0.5102\n",
      "9/13, Loss: 0.8056, Acc:0.5076\n",
      "10/13, Loss: 0.8064, Acc:0.5069\n",
      "11/13, Loss: 0.8002, Acc:0.5131\n",
      "12/13, Loss: 0.8044, Acc:0.5089\n",
      "13/13, Loss: 0.8027, Acc:0.5106\n",
      "train Loss:0.8041 Acc:0.5092\n",
      "complete in 1m 52 s\n",
      "\n",
      "8/10\n",
      "----------\n",
      "1/13, Loss: 0.7883, Acc:0.5250\n",
      "2/13, Loss: 0.7695, Acc:0.5437\n",
      "3/13, Loss: 0.7883, Acc:0.5250\n",
      "4/13, Loss: 0.7867, Acc:0.5266\n",
      "5/13, Loss: 0.7883, Acc:0.5250\n",
      "6/13, Loss: 0.7956, Acc:0.5177\n",
      "7/13, Loss: 0.8088, Acc:0.5045\n",
      "8/13, Loss: 0.8078, Acc:0.5055\n",
      "9/13, Loss: 0.8015, Acc:0.5118\n",
      "10/13, Loss: 0.7995, Acc:0.5138\n",
      "11/13, Loss: 0.7968, Acc:0.5165\n",
      "12/13, Loss: 0.8008, Acc:0.5125\n",
      "13/13, Loss: 0.8041, Acc:0.5091\n",
      "train Loss:0.8036 Acc:0.5097\n",
      "complete in 1m 52 s\n",
      "\n",
      "9/10\n",
      "----------\n",
      "1/13, Loss: 0.8383, Acc:0.4750\n",
      "2/13, Loss: 0.8476, Acc:0.4656\n",
      "3/13, Loss: 0.8299, Acc:0.4833\n",
      "4/13, Loss: 0.8086, Acc:0.5047\n",
      "5/13, Loss: 0.8120, Acc:0.5012\n",
      "6/13, Loss: 0.8153, Acc:0.4979\n",
      "7/13, Loss: 0.8017, Acc:0.5116\n",
      "8/13, Loss: 0.8039, Acc:0.5094\n",
      "9/13, Loss: 0.8015, Acc:0.5118\n",
      "10/13, Loss: 0.8001, Acc:0.5131\n",
      "11/13, Loss: 0.7996, Acc:0.5136\n",
      "12/13, Loss: 0.7976, Acc:0.5156\n",
      "13/13, Loss: 0.8008, Acc:0.5125\n",
      "train Loss:0.8017 Acc:0.5116\n",
      "complete in 1m 51 s\n",
      "\n",
      "10/10\n",
      "----------\n",
      "1/13, Loss: 0.8320, Acc:0.4813\n",
      "2/13, Loss: 0.8289, Acc:0.4844\n",
      "3/13, Loss: 0.8091, Acc:0.5042\n",
      "4/13, Loss: 0.8179, Acc:0.4953\n",
      "5/13, Loss: 0.8095, Acc:0.5038\n",
      "6/13, Loss: 0.8122, Acc:0.5010\n",
      "7/13, Loss: 0.8106, Acc:0.5027\n",
      "8/13, Loss: 0.8125, Acc:0.5008\n",
      "9/13, Loss: 0.8119, Acc:0.5014\n",
      "10/13, Loss: 0.8058, Acc:0.5075\n",
      "11/13, Loss: 0.8053, Acc:0.5080\n",
      "12/13, Loss: 0.8044, Acc:0.5089\n",
      "13/13, Loss: 0.8046, Acc:0.5087\n",
      "train Loss:0.8022 Acc:0.5111\n",
      "complete in 1m 51 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epoch): # 开始每个epoch\n",
    "    since = time.time() # 取得当前时间\n",
    "    print('{}/{}'.format(epoch+1, num_epoch))\n",
    "    print('-'*10)\n",
    "\n",
    "#     for phase in ['train', 'val']: # 判断是train还是validation\n",
    "#     if phase == 'train':\n",
    "    optimizer.zero_grad() # 将梯度归零\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    for i, data in enumerate(dataloader['train'], 1):\n",
    "        img, label = data\n",
    "        if use_gpu:\n",
    "            img = Variable(img).cuda()\n",
    "            label = Variable(label).cuda()\n",
    "        else:\n",
    "            img = Variable(img)\n",
    "            label = Variable(label)\n",
    "\n",
    "        # forward\n",
    "        output = mynet(img)\n",
    "        _, pred = torch.max(output, 1)\n",
    "        loss = criterion(output, label)\n",
    "        # backward\n",
    "#         if phase == 'train': # 如果是train，则反向传播更新参数\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # log statistics\n",
    "        running_loss += loss.data[0] * label.size(0)\n",
    "        num_correct = torch.sum(pred == label)\n",
    "        running_acc += num_correct.data[0]\n",
    "        if i % 10 == 0:\n",
    "            print('{}/{}, Loss: {:.4f}, Acc:{:.4f}'.format(i//10, data_size['train']//(10*16), \n",
    "                                                   running_loss/(i*16), running_acc/(i*16)))\n",
    "        \n",
    "    running_loss /= data_size['train']\n",
    "    running_acc /= data_size['train']\n",
    "    print('{} Loss:{:.4f} Acc:{:.4f}'.format('train', running_loss, running_acc))\n",
    "    time_eplise = time.time() - since\n",
    "    print('complete in {:.0f}m {:.0f} s'.format(time_eplise//60, time_eplise%60))\n",
    "#             if phase == 'val' and running_acc > best_acc: # 根据validation 判断更新之后的model是否更好\n",
    "#                 best_acc = running_acc\n",
    "#                 best_model = copy.deepcopy(model)\n",
    "\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "#     best_model = model\n",
    "#     best_acc = 0.0\n",
    "        \n",
    "for epoch in range(num_epoch): # 开始每个epoch\n",
    "    since = time.time() # 取得当前时间\n",
    "    print('{}/{}'.format(epoch+1, num_epoch))\n",
    "    print('-'*10)\n",
    "\n",
    "    for phase in ['train', 'val']: # 判断是train还是validation\n",
    "        if phase == 'train':\n",
    "            optimizer.zero_grad() # 将梯度归零\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        for data in dataloader[phase]:\n",
    "            img, label = data\n",
    "            if use_gpu:\n",
    "                img = Variable(img).cuda()\n",
    "                label = Variable(label).cuda()\n",
    "            else:\n",
    "                img = Variable(img)\n",
    "                label = Variable(label)\n",
    "\n",
    "            # forward\n",
    "            output = mynet(img)\n",
    "            _, pred = torch.max(output, 1)\n",
    "            loss = criterion(output, label)\n",
    "            # backward\n",
    "            if phase == 'train': # 如果是train，则反向传播更新参数\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            # log statistics\n",
    "            running_loss += loss.data[0] * label.size(0)\n",
    "            num_correct = torch.sum(pred == label)\n",
    "            running_acc += num_correct.data[0]\n",
    "\n",
    "        running_loss /= data_size[phase]\n",
    "        running_acc /= data_size[phase]\n",
    "        print('{} Loss:{:.4f} Acc:{:.4f}'.format(phase, running_loss, running_acc))\n",
    "    time_eplise = time.time() - since\n",
    "    print('comlete in {:.0f}m{:.0f}s'.format(epoch+1, num_epoch,time_eplise//60, time_eplise%60))\n",
    "#             if phase == 'val' and running_acc > best_acc: # 根据validation 判断更新之后的model是否更好\n",
    "#                 best_acc = running_acc\n",
    "#                 best_model = copy.deepcopy(model)\n",
    "\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
